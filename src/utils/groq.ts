import Groq from 'groq-sdk';
import { KnownError } from './error.js';
import type { CommitType } from './config.js';
import { generatePrompt } from './prompt.js';
import { chunkDiff, splitDiffByFile, estimateTokenCount } from './git.js';

const createChatCompletion = async (
	apiKey: string,
	model: string,
	messages: Array<{ role: string; content: string }>,
	temperature: number,
	top_p: number,
	frequency_penalty: number,
	presence_penalty: number,
	max_tokens: number,
	n: number,
	timeout: number,
	proxy?: string
) => {
	const client = new Groq({
		apiKey,
		timeout,
	});

	try {
		if (n > 1) {
			const completions = await Promise.all(
				Array.from({ length: n }, () =>
					client.chat.completions.create({
						model,
						messages: messages as any,
						temperature,
						top_p,
						frequency_penalty,
						presence_penalty,
						max_tokens,
						n: 1,
					})
				)
			);
			
			return {
				choices: completions.flatMap(completion => completion.choices),
			};
		}

		const completion = await client.chat.completions.create({
			model,
			messages: messages as any,
			temperature,
			top_p,
			frequency_penalty,
			presence_penalty,
			max_tokens,
			n: 1,
		});

		return completion;
	} catch (error: any) {
		if (error instanceof Groq.APIError) {
			let errorMessage = `Groq API Error: ${error.status} - ${error.name}`;
			
			if (error.message) {
				errorMessage += `\n\n${error.message}`;
			}

			if (error.status === 500) {
				errorMessage += '\n\nCheck the API status: https://console.groq.com/status';
			}

			if (error.status === 413 || (error.message && error.message.includes('rate_limit_exceeded'))) {
				errorMessage += '\n\nðŸ’¡ Tip: Your diff is too large. Try:\n' +
					'1. Commit files in smaller batches\n' +
					'2. Exclude large files with --exclude\n' +
					'3. Use a different model with --model\n' +
					'4. Check if you have build artifacts staged (dist/, .next/, etc.)';
			}

			throw new KnownError(errorMessage);
		}

		if (error.code === 'ENOTFOUND') {
			throw new KnownError(
				`Error connecting to ${error.hostname} (${error.syscall}). Are you connected to the internet?`
			);
		}

		throw error;
	}
};

const sanitizeMessage = (message: string) =>
	message
		.trim()
		.replace(/[\n\r]/g, '')
		.replace(/(\w)\.$/, '$1');

const deduplicateMessages = (array: string[]) => Array.from(new Set(array));

const conventionalPrefixes = [
    'feat:', 'fix:', 'docs:', 'style:', 'refactor:', 'perf:', 'test:', 'build:', 'ci:', 'chore:', 'revert:'
];

const deriveMessageFromReasoning = (text: string, maxLength: number): string | null => {
    const cleaned = text.replace(/\s+/g, ' ').trim();
    // Try to find a conventional-style line inside reasoning
    const match = cleaned.match(/\b(feat|fix|docs|style|refactor|perf|test|build|ci|chore|revert)\b\s*:?\s+[^.\n]+/i);
    let candidate = match ? match[0] : cleaned.split(/[.!?]/)[0];
    // Ensure prefix formatting: if starts with a known type w/o colon, add colon
    const lower = candidate.toLowerCase();
    for (const prefix of conventionalPrefixes) {
        const p = prefix.slice(0, -1); // without colon
        if (lower.startsWith(p + ' ') && !lower.startsWith(prefix)) {
            candidate = p + ': ' + candidate.slice(p.length + 1);
            break;
        }
    }
    candidate = sanitizeMessage(candidate);
    if (!candidate) return null;
    if (candidate.length > maxLength) candidate = candidate.slice(0, maxLength);
    return candidate;
};

export const generateCommitMessage = async (
	apiKey: string,
	model: string,
	locale: string,
	diff: string,
	completions: number,
	maxLength: number,
	type: CommitType,
	timeout: number,
	proxy?: string
) => {
	try {
		const completion = await createChatCompletion(
			apiKey,
			model,
			[
				{
					role: 'system',
					content: generatePrompt(locale, maxLength, type),
				},
				{
					role: 'user',
					content: diff,
				},
			],
			0.7,
			1,
			0,
			0,
			Math.max(200, maxLength * 8),
			completions,
			timeout,
			proxy
		);

        const messages = completion.choices
            .map((choice) => choice.message?.content || '')
            .map((text) => sanitizeMessage(text as string))
            .filter(Boolean);

        if (messages.length > 0) return deduplicateMessages(messages);

        // Fallback: some Groq models return reasoning with an empty content
        const reasoningCandidates = (completion.choices as any[])
            .map((c) => (c as any).message?.reasoning || '')
            .filter(Boolean) as string[];
        for (const reason of reasoningCandidates) {
            const derived = deriveMessageFromReasoning(reason, maxLength);
            if (derived) return [derived];
        }

        return [];
	} catch (error) {
		const errorAsAny = error as any;
		if (errorAsAny.code === 'ENOTFOUND') {
			throw new KnownError(
				`Error connecting to ${errorAsAny.hostname} (${errorAsAny.syscall}). Are you connected to the internet?`
			);
		}

		throw errorAsAny;
	}
};

export const generateCommitMessageFromChunks = async (
	apiKey: string,
	model: string,
	locale: string,
	diff: string,
	completions: number,
	maxLength: number,
	type: CommitType,
	timeout: number,
	proxy?: string,
	chunkSize: number = 6000
) => {
    // Strategy: split by file first to avoid crossing file boundaries
    const fileDiffs = splitDiffByFile(diff);
    const perFileChunks = fileDiffs.flatMap(fd => chunkDiff(fd, chunkSize));
    const chunks = perFileChunks.length > 0 ? perFileChunks : chunkDiff(diff, chunkSize);
	
	if (chunks.length === 1) {
		try {
			return await generateCommitMessage(
				apiKey,
				model,
				locale,
				diff,
				completions,
				maxLength,
				type,
				timeout,
				proxy
			);
		} catch (error) {
			throw new KnownError(`Failed to generate commit message: ${error instanceof Error ? error.message : 'Unknown error'}`);
		}
	}

	// Multiple chunks - generate commit messages for each chunk
	const chunkMessages: string[] = [];
	
    for (let i = 0; i < chunks.length; i++) {
		const chunk = chunks[i];
        const approxInputTokens = estimateTokenCount(chunk) + 1200; // reserve for prompt/system
        let effectiveMaxTokens = Math.max(200, maxLength * 8);
        // If close to model limit, reduce output tokens
        if (approxInputTokens + effectiveMaxTokens > 7500) {
            effectiveMaxTokens = Math.max(200, 7500 - approxInputTokens);
        }

        const chunkPrompt = `Analyze this git diff and propose a concise commit message limited to ${maxLength} characters. Focus on the most significant intent of the change.\n\n${chunk}`;

		try {
            const messages = await createChatCompletion(
				apiKey,
				model,
                [
                    { role: 'system', content: generatePrompt(locale, maxLength, type) },
                    { role: 'user', content: chunkPrompt },
                ],
                0.7,
                1,
                0,
                0,
                effectiveMaxTokens,
                1,
                timeout,
                proxy
            );
			
            const texts = (messages.choices || [])
                .map(c => c.message?.content)
                .filter(Boolean) as string[];
            if (texts.length > 0) {
                chunkMessages.push(sanitizeMessage(texts[0]));
            } else {
                const reasons = (messages.choices as any[]).map((c:any)=>c.message?.reasoning || '').filter(Boolean) as string[];
                if (reasons.length > 0) {
                    const derived = deriveMessageFromReasoning(reasons[0], maxLength);
                    if (derived) chunkMessages.push(derived);
                }
            }
		} catch (error) {
			console.warn(`Failed to process chunk ${i + 1}:`, error instanceof Error ? error.message : 'Unknown error');
		}
	}

    if (chunkMessages.length === 0) {
        // Fallback: summarize per-file names only to craft a high-level message
        const fileNames = splitDiffByFile(diff)
            .map(block => {
                const first = block.split('\n', 1)[0] || '';
                const parts = first.split(' ');
                return parts[2]?.replace('a/', '') || '';
            })
            .filter(Boolean)
            .slice(0, 15);

        const fallbackPrompt = `Generate a single, concise commit message (<= ${maxLength} chars) summarizing changes across these files:\n${fileNames.map(f => `- ${f}`).join('\n')}`;

        try {
            const completion = await createChatCompletion(
                apiKey,
                model,
                [
                    { role: 'system', content: generatePrompt(locale, maxLength, type) },
                    { role: 'user', content: fallbackPrompt },
                ],
                0.7,
                1,
                0,
                0,
                Math.max(200, maxLength * 8),
                1,
                timeout,
                proxy
            );
            const texts = (completion.choices || [])
                .map(c => c.message?.content)
                .filter(Boolean) as string[];
            if (texts.length > 0) return [sanitizeMessage(texts[0])];
        } catch {}

        throw new KnownError('Failed to generate commit messages for any chunks');
    }

	// If we have multiple chunk messages, try to combine them intelligently
	if (chunkMessages.length > 1) {
		const combinedPrompt = `I have ${chunkMessages.length} commit messages for different parts of a large change:

${chunkMessages.map((msg, i) => `${i + 1}. ${msg}`).join('\n')}

Please generate a single, comprehensive commit message that captures the overall changes. 
The message should be concise but cover the main aspects of all the changes.`;

		try {
			const combinedMessages = await generateCommitMessage(
				apiKey,
				model,
				locale,
				combinedPrompt,
				completions,
				maxLength,
				type,
				timeout,
				proxy
			);
			
			return combinedMessages;
		} catch (error) {
			// If combining fails, return the individual chunk messages
			return chunkMessages;
		}
	}

	return chunkMessages;
};
